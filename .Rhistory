rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
EPL0809 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL08-09.csv")
EPL0910 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL09-10.csv")
EPL1011 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL10-11.csv")
EPL1112 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL11-12.csv")
EPL1213 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL12-13.csv")
EPL1314 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL13-14.csv")
EPL1415 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL14-15.csv")
EPL1516 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL15-16.csv")
EPL1617 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL16-17.csv")
EPL1718 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL17-18.csv")
EPL1819 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL18-19.csv")
EPL1920 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL19-20.csv")
EPL2021 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL20-21.csv")
EPL2122 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL21-22.csv")
EPL2223 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL22-23.csv")
EPL2324 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL23-24.csv")
EPL2425 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL24-25.csv")
knitr::opts_chunk$set(echo = TRUE)
EPL0809 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL08-09.csv")
EPL0910 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL09-10.csv")
EPL1011 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL10-11.csv")
EPL1112 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL11-12.csv")
EPL1213 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL12-13.csv")
EPL1314 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL13-14.csv")
EPL1415 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL14-15.csv")
EPL1516 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL15-16.csv")
EPL1617 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL16-17.csv")
EPL1718 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL17-18.csv")
EPL1819 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL18-19.csv")
EPL1920 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL19-20.csv")
EPL2021 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL20-21.csv")
EPL2122 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL21-22.csv")
EPL2223 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL22-23.csv")
EPL2324 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL23-24.csv")
EPL2425 <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL24-25.csv")
# Create a list of all dataframes
epl_list <- list(EPL0809, EPL0910, EPL1011, EPL1112, EPL1213, EPL1314, EPL1415,
EPL1516, EPL1617, EPL1718, EPL1819, EPL1920, EPL2021, EPL2122, EPL2223, EPL2324, EPL2425)
# Get all unique column names across datasets
all_columns <- unique(unlist(lapply(epl_list, colnames)))
# Standardize columns in each dataset
epl_list <- lapply(epl_list, function(df) {
missing_cols <- setdiff(all_columns, colnames(df)) # Identify missing columns
df[missing_cols] <- NA                             # Add missing columns with NA
df <- df[, all_columns]                            # Reorder columns to match all_columns
return(df)
})
# Combine all datasets
epl_combined <- do.call(rbind, epl_list)
# Preview the combined dataset
head(epl_combined)
#View(epl_combined)
write.csv(epl_combined, "C:/Users/brian/Downloads/EPL_combined_2008-2025.csv", row.names = FALSE)
# Create a list of all dataframes
epl_list <- list(EPL0809, EPL0910, EPL1011, EPL1112, EPL1213, EPL1314, EPL1415,
EPL1516, EPL1617, EPL1718, EPL1819, EPL1920, EPL2021, EPL2122, EPL2223, EPL2324, EPL2425)
# Get all unique column names across datasets
all_columns <- unique(unlist(lapply(epl_list, colnames)))
# Standardize columns in each dataset
epl_list <- lapply(epl_list, function(df) {
missing_cols <- setdiff(all_columns, colnames(df)) # Identify missing columns
df[missing_cols] <- NA                             # Add missing columns with NA
df <- df[, all_columns]                            # Reorder columns to match all_columns
return(df)
})
# Combine all datasets
epl_combined <- do.call(rbind, epl_list)
# Preview the combined dataset
head(epl_combined)
#View(epl_combined)
write.csv(epl_combined, "C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL_combined_2008-2025.csv", row.names = FALSE)
# Load the combined dataset
soccer_data <- read.csv("C:/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL_combined_2008-2025.csv")
# Load the combined dataset
soccer_data <- read.csv("C:/asada/OneDrive/Desktop/Projects/premier-league-betting/Projects/datasets/EPL_combined_2008-2025.csv")
# Load the combined dataset
soccer_data <- read.csv("C:/Users/asada/OneDrive/Desktop/Projects/premier-league-betting/datasets/EPL_combined_2008-2025.csv")
# Set threshold for missing values
threshold <- 0.9
cols_to_keep <- colSums(is.na(soccer_data)) / nrow(soccer_data) < threshold
# Keep only relevant columns
soccer_cleaned <- soccer_data[, cols_to_keep]
# Preview cleaned dataset
print(paste("Columns kept:", sum(cols_to_keep), "/", ncol(soccer_data)))
library(lubridate)
soccer_cleaned$Date <- dmy(soccer_cleaned$Date)
# Remove rows with invalid or missing dates
soccer_cleaned <- soccer_cleaned[!is.na(soccer_cleaned$Date), ]
# Add GoalDifference column
soccer_cleaned$GoalDifference <- soccer_cleaned$FTHG - soccer_cleaned$FTAG
# Add Outcome column
soccer_cleaned$Outcome <- factor(
ifelse(soccer_cleaned$FTR == "H", "Win",
ifelse(soccer_cleaned$FTR == "A", "Loss", "Draw"))
)
# Keep only relevant columns
relevant_columns <- c("Date", "HomeTeam", "AwayTeam", "FTHG", "FTAG",
"GoalDifference", "Outcome", "HS", "AS", "HST", "AST",
"B365H", "B365D", "B365A")
soccer_cleaned <- soccer_cleaned[, relevant_columns]
# Summary of the cleaned dataset
summary(soccer_cleaned)
# Check for remaining missing values
print(colSums(is.na(soccer_cleaned)))
# Save cleaned dataset (optional)
write.csv(soccer_cleaned, "cleaned_soccer_data.csv", row.names = FALSE)
# Load necessary library
library(dplyr)
library(zoo)  # For rolling averages
# Function to calculate rolling averages for team performance
add_rolling_metrics <- function(data, team_col, goals_col, conceded_col, is_home) {
data %>%
arrange(Date) %>%
group_by(!!sym(team_col)) %>%
mutate(
RollingGoalsScored = rollapply(
!!sym(goals_col), width = 5, FUN = mean, align = "right", fill = NA
),
RollingGoalsConceded = rollapply(
!!sym(conceded_col), width = 5, FUN = mean, align = "right", fill = NA
)
) %>%
ungroup()
}
# Add rolling metrics for Home and Away teams
soccer_cleaned <- soccer_cleaned %>%
add_rolling_metrics("HomeTeam", "FTHG", "FTAG", TRUE) %>%
add_rolling_metrics("AwayTeam", "FTAG", "FTHG", FALSE)
# Add rolling metrics for Home and Away teams
soccer_cleaned <- soccer_cleaned %>%
arrange(Date) %>%
group_by(HomeTeam) %>%
mutate(
HomeRollingGoalsScored = rollapply(FTHG, width = 5, FUN = mean, align = "right", fill = NA),
HomeRollingGoalsConceded = rollapply(FTAG, width = 5, FUN = mean, align = "right", fill = NA)
) %>%
ungroup() %>%
group_by(AwayTeam) %>%
mutate(
AwayRollingGoalsScored = rollapply(FTAG, width = 5, FUN = mean, align = "right", fill = NA),
AwayRollingGoalsConceded = rollapply(FTHG, width = 5, FUN = mean, align = "right", fill = NA)
) %>%
ungroup()
# Check for the newly added columns
names(soccer_cleaned)
# Remove rows with NA values in rolling metrics
soccer_cleaned <- soccer_cleaned %>%
filter(
!is.na(HomeRollingGoalsScored) &
!is.na(AwayRollingGoalsScored)
)
final_dataset <- soccer_cleaned %>%
select(Date, HomeTeam, AwayTeam, Outcome,
HomeRollingGoalsScored, HomeRollingGoalsConceded,
AwayRollingGoalsScored, AwayRollingGoalsConceded,
B365H, B365D, B365A)
set.seed(123)  # For reproducibility
train_indices <- sample(1:nrow(final_dataset), size = 0.8 * nrow(final_dataset))
train_data <- final_dataset[train_indices, ]
test_data <- final_dataset[-train_indices, ]
# Load libraries
library(randomForest)
library(caret)  # For evaluating model performance
class(train_data$Date)
class(test_data$Date)
# Train Random Forest model
set.seed(123)  # For reproducibility
rf_model <- randomForest(
Outcome ~ HomeRollingGoalsScored + HomeRollingGoalsConceded +
AwayRollingGoalsScored + AwayRollingGoalsConceded +
B365H + B365D + B365A,
data = train_data,
ntree = 500,    # Number of trees
mtry = 3,       # Number of variables tried at each split
importance = TRUE
)
# Print model summary
#print(rf_model)
oob_error <- rf_model$err.rate[, 1]  # First column for OOB error
# Create a data frame for plotting
#plot_dat <- data.frame(trees = 1:length(oob_error), oob_error = oob_error)
# Plot OOB error vs number of trees
#plot(plot_dat$trees, plot_dat$oob_error, type = "l", col = "blue",
#     xlab = "Number of Trees", ylab = "OOB Error Rate",
#     main = "OOB Error vs Number of Trees")
#g_2 <- ggplot(plot_dat, aes(x = trees, y = oob_error)) + # Set x as trees and y as error
#  geom_point(alpha = 0.5, color = "blue") + # Select geom point
#  geom_smooth() + # Add smoothing line
#  theme_bw() + # Set theme
#  theme(panel.grid.major = element_blank(), # Remove grid
#        panel.grid.minor = element_blank(), # Remove grid
#        panel.border = element_blank(), # Remove grid
#        panel.background = element_blank()) + # Remove grid
#  labs(x = "Number of Trees", title = "Error Rate v Number of Trees",
#       y = "Error Rate")  # Set labels
#g_2
oob_error <- rf_model$err.rate[, 1]  # First column for OOB error
# Create a data frame for plotting
plot_dat <- data.frame(trees = 1:length(oob_error), oob_error = oob_error)
# Plot OOB error vs number of trees
plot(plot_dat$trees, plot_dat$oob_error, type = "l", col = "blue",
xlab = "Number of Trees", ylab = "OOB Error Rate",
main = "OOB Error vs Number of Trees")
g_2 <- ggplot(plot_dat, aes(x = trees, y = oob_error)) + # Set x as trees and y as error
geom_point(alpha = 0.5, color = "blue") + # Select geom point
geom_smooth() + # Add smoothing line
theme_bw() + # Set theme
theme(panel.grid.major = element_blank(), # Remove grid
panel.grid.minor = element_blank(), # Remove grid
panel.border = element_blank(), # Remove grid
panel.background = element_blank()) + # Remove grid
labs(x = "Number of Trees", title = "Error Rate v Number of Trees",
y = "Error Rate")  # Set labels
g_2
print(rf_model)
# Predict on test data
rf_predictions <- predict(rf_model, test_data)
# Confusion Matrix
conf_matrix <- table(Predicted = rf_predictions, Actual = test_data$Outcome)
print(conf_matrix)
# Calculate Accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
error_rate <- 1 - accuracy
# Print results
print(paste("Test Accuracy:", round(accuracy * 100, 2), "%"))
print(paste("Test Error Rate:", round(error_rate * 100, 2), "%"))
# Predict on test data
rf_predictions <- predict(rf_model, test_data)
# Confusion matrix and accuracy
conf_matrix <- confusionMatrix(rf_predictions, test_data$Outcome)
print(conf_matrix)
# Plot feature importance
varImpPlot(rf_model)
# Numerical importance values
importance_values <- importance(rf_model)
print(importance_values)
# Feature importance as a bar chart
importance_values <- importance(rf_model)
barplot(importance_values[, "MeanDecreaseAccuracy"],
main = "Feature Importance (Mean Decrease in Accuracy)",
horiz = TRUE, las = 1, col = "blue")
# Analyze misclassified samples
misclassified <- test_data[rf_predictions != test_data$Outcome, ]
print(misclassified)
# Distribution of true vs. predicted classes
table(True = test_data$Outcome, Predicted = rf_predictions)
library(caret)
t1 <- table(True = test_data$Outcome, Predicted = rf_predictions)
confusionMatrix(t1)
# Function to interactively input teams and odds and predict the outcome
predict_interactive <- function(model, dataset) {
# Input home and away teams
home_team <- readline(prompt = "Enter the Home Team: ")
away_team <- readline(prompt = "Enter the Away Team: ")
# Input betting odds
odds_home <- as.numeric(readline(prompt = "Enter odds for Home Win: "))
odds_draw <- as.numeric(readline(prompt = "Enter odds for Draw: "))
odds_away <- as.numeric(readline(prompt = "Enter odds for Away Win: "))
# Extract relevant data for the teams
home_data <- dataset %>% filter(HomeTeam == home_team) %>% slice_tail(n = 1)
away_data <- dataset %>% filter(AwayTeam == away_team) %>% slice_tail(n = 1)
# If no data for the teams, return error
if (nrow(home_data) == 0 || nrow(away_data) == 0) {
return(paste("No data available for", home_team, "vs", away_team))
}
# Combine rolling metrics and input odds into a prediction row
prediction_row <- tibble(
HomeRollingGoalsScored = home_data$HomeRollingGoalsScored,
HomeRollingGoalsConceded = home_data$HomeRollingGoalsConceded,
AwayRollingGoalsScored = away_data$AwayRollingGoalsScored,
AwayRollingGoalsConceded = away_data$AwayRollingGoalsConceded,
B365H = odds_home,
B365D = odds_draw,
B365A = odds_away
)
# Predict outcome using the model
predicted_outcome <- predict(model, prediction_row)
# Return the prediction
return(paste("Predicted Outcome for", home_team, "vs", away_team, ":", predicted_outcome))
}
# Example usage
prediction <- predict_interactive(model = rf_model, dataset = final_dataset)
print(prediction)
View(epl_combined)
# Function to interactively input teams and odds and predict the outcome
predict_interactive <- function(model, dataset) {
# Input home and away teams
home_team <- readline(prompt = "Enter the Home Team: ")
away_team <- readline(prompt = "Enter the Away Team: ")
# Input betting odds
odds_home <- as.numeric(readline(prompt = "Enter odds for Home Win: "))
odds_draw <- as.numeric(readline(prompt = "Enter odds for Draw: "))
odds_away <- as.numeric(readline(prompt = "Enter odds for Away Win: "))
# Extract relevant data for the teams
home_data <- dataset %>% filter(HomeTeam == home_team) %>% slice_tail(n = 1)
away_data <- dataset %>% filter(AwayTeam == away_team) %>% slice_tail(n = 1)
# If no data for the teams, return error
if (nrow(home_data) == 0 || nrow(away_data) == 0) {
return(paste("No data available for", home_team, "vs", away_team))
}
# Combine rolling metrics and input odds into a prediction row
prediction_row <- tibble(
HomeRollingGoalsScored = home_data$HomeRollingGoalsScored,
HomeRollingGoalsConceded = home_data$HomeRollingGoalsConceded,
AwayRollingGoalsScored = away_data$AwayRollingGoalsScored,
AwayRollingGoalsConceded = away_data$AwayRollingGoalsConceded,
B365H = odds_home,
B365D = odds_draw,
B365A = odds_away
)
# Predict outcome using the model
predicted_outcome <- predict(model, prediction_row)
# Return the prediction
return(paste("Predicted Outcome for", home_team, "vs", away_team, ":", predicted_outcome))
}
# Example usage
prediction <- predict_interactive(model = rf_model, dataset = final_dataset)
print(prediction)
# Function to interactively input teams and odds and predict the outcome
predict_interactive <- function(model, dataset) {
# Input home and away teams
home_team <- readline(prompt = "Enter the Home Team: ")
away_team <- readline(prompt = "Enter the Away Team: ")
# Input betting odds
odds_home <- as.numeric(readline(prompt = "Enter odds for Home Win: "))
odds_draw <- as.numeric(readline(prompt = "Enter odds for Draw: "))
odds_away <- as.numeric(readline(prompt = "Enter odds for Away Win: "))
# Extract relevant data for the teams
home_data <- dataset %>% filter(HomeTeam == home_team) %>% slice_tail(n = 1)
away_data <- dataset %>% filter(AwayTeam == away_team) %>% slice_tail(n = 1)
# If no data for the teams, return error
if (nrow(home_data) == 0 || nrow(away_data) == 0) {
return(paste("No data available for", home_team, "vs", away_team))
}
# Combine rolling metrics and input odds into a prediction row
prediction_row <- tibble(
HomeRollingGoalsScored = home_data$HomeRollingGoalsScored,
HomeRollingGoalsConceded = home_data$HomeRollingGoalsConceded,
AwayRollingGoalsScored = away_data$AwayRollingGoalsScored,
AwayRollingGoalsConceded = away_data$AwayRollingGoalsConceded,
B365H = odds_home,
B365D = odds_draw,
B365A = odds_away
)
# Predict outcome using the model
predicted_outcome <- predict(model, prediction_row)
# Return the prediction
return(paste("Predicted Outcome for", home_team, "vs", away_team, ":", predicted_outcome))
}
# Example usage
prediction <- predict_interactive(model = rf_model, dataset = final_dataset)
print(prediction)
